# ğŸ§  Project 7/20 â€“ RecallGPT: Enhancing Small Language Models with Persistent Long-Term Memory

*Part of my **100 Days of Code â€“ Portfolio Project Series***

> **AI Chatbot with Long-Term Memory**  
> Intelligent conversations powered by hybrid semantic retrieval and token-aware memory management.

[![Status](https://img.shields.io/badge/Status-Active-success)](https://github.com/KaustubhMukdam/RecallGPT)
[![Python](https://img.shields.io/badge/Python-3.11+-blue)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green)](https://fastapi.tiangolo.com/)
[![License](https://img.shields.io/badge/License-MIT-yellow)](LICENSE)

ğŸ”— **GitHub Repo:** [RecallGPT](https://github.com/KaustubhMukdam/RecallGPT)

---

## âœ¨ Features

| Feature | Description |
|---------|-------------|
| ğŸ§  **Long-Term Memory** | Hybrid retrieval combining semantic similarity + recency ranking |
| ğŸ’¬ **Multi-Turn Conversations** | Maintains context across 10â€“20+ messages seamlessly |
| ğŸ” **Secure Authentication** | API key-based access for protected endpoints |
| ğŸ“Š **Analytics Dashboard** | Track usage metrics, token counts, and retrieval stats |
| ğŸ¨ **Modern UI** | Claude/Perplexity-inspired clean chat interface |
| âš¡ **Fast & Scalable** | Token-aware context management prevents cutoffs |
| ğŸ”„ **Thread Management** | Manage multiple conversation threads per user |

---

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.11+**
- **Ollama** for local LLM inference
- **4GB+ RAM** recommended

### Installation

```bash
# 1. Clone the repository
git clone https://github.com/KaustubhMukdam/RecallGPT.git
cd RecallGPT

# 2. Create a virtual environment
python -m venv venv
source venv/bin/activate   # Windows: .\venv\Scripts\activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Set up environment variables
cp .env.example .env
# Edit .env with your configuration
```

### Run Ollama (Required)

**1. Install Ollama**  
Download from [https://ollama.ai](https://ollama.ai)

**2. Pull the model**
```bash
ollama pull qwen2.5-coder:1.5b
```

### Start the Application

```bash
cd recallgpt
python api_server.py
```

ğŸ‰ **Open your browser at:** [http://localhost:8000](http://localhost:8000)

---

## ğŸ“‚ Project Structure

```
RecallGPT/
â”œâ”€â”€ recallgpt/
â”‚   â”œâ”€â”€ api_server.py           # FastAPI REST API
â”‚   â”œâ”€â”€ memory_manager.py       # Hybrid retrieval & memory system
â”‚   â”œâ”€â”€ db_manager.py           # SQLite database management
â”‚   â”œâ”€â”€ llm_interface.py        # Ollama LLM integration
â”‚   â”œâ”€â”€ auth_manager.py         # API key authentication logic
â”‚   â”œâ”€â”€ auth_routes.py          # Auth endpoints
â”‚   â”œâ”€â”€ static/                 # Frontend assets
â”‚   â”‚   â”œâ”€â”€ index.html
â”‚   â”‚   â”œâ”€â”€ style.css
â”‚   â”‚   â””â”€â”€ script.js
â”‚   â”œâ”€â”€ recallgpt.db            # Auto-created SQLite DB
â”‚   â””â”€â”€ retrieval_logs.jsonl    # Analytics logs
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_api.py
â”‚   â”œâ”€â”€ test_token_counting.py
â”‚   â””â”€â”€ test_logging_analytics.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## âš™ï¸ Configuration

### Environment Variables (`.env`)

```env
DATABASE_URL=recallgpt.db
API_HOST=0.0.0.0
API_PORT=8000
LLM_MODEL=qwen2.5-coder:1.5b
API_KEY_ENABLED=True
SECRET_KEY=your-secret-key-here
```

---

## ğŸ“– Usage

### Generate API Key

```bash
curl -X POST http://localhost:8000/auth/generate-key \
  -H "Content-Type: application/json" \
  -d '{"user_id": "your_id", "name": "My Key"}'
```

### Create Conversation Thread

```bash
curl -X POST http://localhost:8000/threads/create \
  -H "Content-Type: application/json" \
  -H "X-API-Key: your_api_key" \
  -d '{"thread_name": "My Conversation"}'
```

### Send Message

```bash
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -H "X-API-Key: your_api_key" \
  -d '{
    "thread_id": 1,
    "message": "Explain Python decorators",
    "max_tokens": 2000,
    "top_k": 20
  }'
```

---

## ğŸ§  Architecture Overview

### ğŸ” Memory System

RecallGPT uses a **hybrid retrieval mechanism** combining:

1. **Semantic Search** â€“ via Sentence Transformers (all-MiniLM-L6-v2)
2. **Recency Ranking** â€“ prioritizes the most recent messages
3. **Hybrid Scoring** â€“ `0.7 Ã— semantic + 0.3 Ã— recency`
4. **Token Window Management** â€“ ensures context fits within model limits

### ğŸ—„ï¸ Database Schema

```sql
CREATE TABLE threads (
    thread_id INTEGER PRIMARY KEY,
    thread_name TEXT,
    created_at TEXT
);

CREATE TABLE messages (
    msg_id INTEGER PRIMARY KEY,
    thread_id INTEGER,
    role TEXT,
    content TEXT,
    embedding BLOB,
    user_id TEXT,
    timestamp TEXT,
    FOREIGN KEY(thread_id) REFERENCES threads(thread_id)
);
```

---

## ğŸ“Š API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | Serve Web UI |
| `/health` | GET | Health check |
| `/auth/generate-key` | POST | Generate API key |
| `/threads/create` | POST | Create conversation thread |
| `/threads/list` | GET | List all threads |
| `/threads/{id}/history` | GET | Fetch conversation history |
| `/chat` | POST | Send message to chatbot |
| `/analytics` | GET | Retrieve usage analytics |

---

## ğŸ¨ UI Features

- **ğŸŒ™ Dark Mode** â€“ Toggle theme with one click
- **ğŸ“‘ Thread Sidebar** â€“ Easy navigation between conversations
- **âš¡ Real-Time Chat** â€“ Instant responses
- **ğŸ“Œ Context Indicator** â€“ Shows retrieved messages count
- **ğŸ”¢ Token Counter** â€“ Track usage dynamically
- **ğŸ“ˆ Analytics Dashboard** â€“ Visualize performance metrics

---

## ğŸ”’ Security

- âœ… API key authentication
- âœ… Thread-safe database connections
- âœ… Pydantic input validation
- âœ… CORS-enabled for web interface
- âœ… Secure environment-based configuration

---

## ğŸ“ˆ Performance

| Metric | Performance |
|--------|-------------|
| **Retrieval Speed** | <100ms for 1000+ messages |
| **Memory Usage** | ~500MB (with embeddings) |
| **Concurrent Threads** | Multiple user sessions supported |
| **Context Efficiency** | Smart token windowing prevents cutoffs |

---

## ğŸ›  Tech Stack

**Backend**
- FastAPI
- Python 3.11
- SQLite

**AI/ML**
- Sentence Transformers
- Ollama (Qwen, Llama)

**Frontend**
- HTML, CSS, JavaScript

**Deployment**
- Uvicorn ASGI server

---

## ğŸ“š Learning Outcomes

Through building RecallGPT, I gained hands-on experience with:

- âœ¨ Building long-term memory systems for small LLMs
- ğŸ” Implementing hybrid RAG pipelines with semantic + recency weighting
- âš¡ Optimizing context windows for token efficiency
- ğŸ—ï¸ Creating a modular FastAPI backend with local LLM integration
- ğŸ—„ï¸ Designing efficient database schemas for conversational AI

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. **Fork** the repo
2. **Create** your branch (`git checkout -b feature/AmazingFeature`)
3. **Commit** your changes (`git commit -m 'Add new feature'`)
4. **Push** to your branch (`git push origin feature/AmazingFeature`)
5. **Submit** a Pull Request ğŸš€

---

## ğŸ“ License

This project is licensed under the **MIT License** â€“ see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

Special thanks to these amazing projects:

- [Sentence Transformers](https://www.sbert.net/) â€“ Semantic embeddings
- [Ollama](https://ollama.ai/) â€“ Local LLM inference
- [FastAPI](https://fastapi.tiangolo.com/) â€“ Backend framework

---

## ğŸ‘¨â€ğŸ’» Author

**Kaustubh Mukdam**

- GitHub: [@KaustubhMukdam](https://github.com/KaustubhMukdam)
- LinkedIn: [Kaustubh Mukdam](https://linkedin.com/in/kaustubh-mukdam)

---

<div align="center">

â­ **If you found this project helpful, consider giving it a star!** â­

Made with â¤ï¸ by Kaustubh Mukdam

</div>